{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0Uuxr7iwBnx"
      },
      "source": [
        "### 🔧 Install Required Libraries\n",
        "This cell installs the necessary packages.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mWwPH4IWhZ3d",
        "outputId": "f8516c21-2d40-4a44-aa84-938219d0a749"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: llama-index-retrievers-bm25 in /usr/local/lib/python3.11/dist-packages (0.5.2)\n",
            "Requirement already satisfied: bm25s<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-retrievers-bm25) (0.2.12)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-retrievers-bm25) (0.12.36)\n",
            "Requirement already satisfied: pystemmer<3.0.0.0,>=2.2.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-retrievers-bm25) (2.2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (1.15.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (2.0.2)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.11.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.1.2)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2025.3.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.9.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (11.2.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.11.4)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.32.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.0.40)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (4.13.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.20.0)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (4.3.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (8.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.2.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.26.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.16.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (24.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.0.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.25.5)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.31.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install -q llama-index-llms-google-genai llama-index pymupdf\n",
        "!pip install -q llama-index-embeddings-huggingface\n",
        "!pip install nest_asyncio\n",
        "!pip install llama-index-retrievers-bm25\n",
        "!pip install -q ipywidgets\n",
        "!apt install tesseract-ocr\n",
        "!pip install pymupdf pytesseract opencv-python pillow\n",
        "!pip install sentence-transformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUllT2HgwH0c"
      },
      "source": [
        "### 🧱 Environment Setup\n",
        "This cell imports all core libraries and configures the Google Gemini API key, along with some utility setup for directory and display.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyknyHvxhltC"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "import cv2\n",
        "import pytesseract\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import fitz\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Markdown, display\n",
        "import nest_asyncio\n",
        "from google.colab import files\n",
        "from llama_index.core import Document\n",
        "from typing import List\n",
        "from llama_index.core.schema import Document, TextNode\n",
        "from llama_index.llms.google_genai import GoogleGenAI\n",
        "from llama_index.core import Settings\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.llms import ChatMessage\n",
        "from llama_index.core.prompts import ChatPromptTemplate\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
        "from llama_index.retrievers.bm25 import BM25Retriever\n",
        "from llama_index.core.retrievers import BaseRetriever\n",
        "from llama_index.core.schema import NodeWithScore, QueryBundle\n",
        "from llama_index.core.retrievers import QueryFusionRetriever\n",
        "from llama_index.core.vector_stores import MetadataFilters, ExactMatchFilter\n",
        "from llama_index.core.text_splitter import SentenceSplitter\n",
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Set up Google API key for Gemini\n",
        "GOOGLE_API_KEY = \"AIzaSyAyNPT5Kl_Y00dOwlAzQ9Y8mzCQSwZN1F4\"  # Replace with your actual API key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "\n",
        "# Create a directory for our PDFs if it doesn't exist\n",
        "!mkdir -p sample_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsmgVyOHwKTt"
      },
      "source": [
        "### ⚙️ RAG Configuration Parameters\n",
        "All major parameters for chunking, retrieval, reranking, and query expansion are centralized in the `rag_config` dictionary for easier tuning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTERkVFep0w1"
      },
      "outputs": [],
      "source": [
        "# RAG configuration for chunking, retrieval, reranking\n",
        "rag_config = {\n",
        "    \"fine_chunk_size\": 256,\n",
        "    \"fine_chunk_overlap\": 20,\n",
        "    \"coarse_chunk_size\": 1024,\n",
        "    \"retrieval_top_k\": 4,\n",
        "    \"rerank_top_n\": 2,\n",
        "    \"num_query_expansions\": 3\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK9-bLN5wMi5"
      },
      "source": [
        "### 📄 Upload PDF\n",
        "This cell allows the user to upload a PDF file that will be used for building the RAG pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "mA8EFEu6hlph",
        "outputId": "d6d55f87-3cbe-409f-ab11-32bf8573502b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please select a PDF file to upload:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b67e25db-0818-4ba1-ae51-c0011d758503\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b67e25db-0818-4ba1-ae51-c0011d758503\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sample_mortgage_document.pdf to sample_mortgage_document (1).pdf\n",
            "PDF saved to sample_docs/sample_mortgage_document (1).pdf\n"
          ]
        }
      ],
      "source": [
        "def upload_pdf():\n",
        "    \"\"\"Upload a PDF file and return its path.\"\"\"\n",
        "    print(\"Please select a PDF file to upload:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        if filename.endswith('.pdf'):\n",
        "            # Save to the sample_docs directory\n",
        "            pdf_path = os.path.join(\"sample_docs\", filename)\n",
        "\n",
        "            # Create directory if it doesn't exist\n",
        "            os.makedirs(\"sample_docs\", exist_ok=True)\n",
        "\n",
        "            # Save the file\n",
        "            with open(pdf_path, 'wb') as f:\n",
        "                f.write(uploaded[filename])\n",
        "\n",
        "            print(f\"PDF saved to {pdf_path}\")\n",
        "            return pdf_path\n",
        "        else:\n",
        "            print(f\"File {filename} is not a PDF. Please upload a PDF file.\")\n",
        "\n",
        "    return None\n",
        "\n",
        "# upload your own PDF\n",
        "pdf_path = upload_pdf()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📘 Load PDF and Extract Text ( PDF Parsing )\n",
        "Uses PyMuPDF to read each page of the uploaded PDF and convert it into structured LlamaIndex `Document` objects with metadata.\n"
      ],
      "metadata": {
        "id": "R-VXtzl3mA9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# 📌 Convert PDF to Images for OCR\n",
        "# =======================\n",
        "def pdf_to_images(pdf_path):\n",
        "    \"\"\"\n",
        "    Convert each page of a PDF file into high-resolution images for OCR.\n",
        "    Returns a list of images, one per page.\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    with fitz.open(pdf_path) as doc:\n",
        "        for page_num in range(len(doc)):\n",
        "            # Extract each page as a high-quality image\n",
        "            pix = doc[page_num].get_pixmap()\n",
        "            img = np.array(Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples))\n",
        "            images.append(img)\n",
        "    return images\n",
        "\n",
        "# =======================\n",
        "# 📌 Preprocess Image for OCR\n",
        "# =======================\n",
        "def preprocess_image(img, show_preview=False):\n",
        "    \"\"\"\n",
        "    Preprocess an image for OCR by enhancing contrast and sharpening.\n",
        "    Uses CLAHE for local contrast normalization and Laplacian filtering for edge enhancement.\n",
        "    \"\"\"\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Apply CLAHE to enhance local contrast\n",
        "    clahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(8, 8))\n",
        "    gray = clahe.apply(gray)\n",
        "\n",
        "    # Apply a mild sharpening filter to enhance edges\n",
        "    sharpening_kernel = np.array([\n",
        "        [0, -1, 0],\n",
        "        [-1, 4.5, -1],\n",
        "        [0, -1, 0]\n",
        "    ])\n",
        "    gray = cv2.filter2D(gray, -1, sharpening_kernel)\n",
        "\n",
        "    # Resize for better OCR accuracy (Tesseract works better on larger text)\n",
        "    scale_percent = 200  # Increase image size by 200%\n",
        "    width = int(gray.shape[1] * scale_percent / 100)\n",
        "    height = int(gray.shape[0] * scale_percent / 100)\n",
        "    gray = cv2.resize(gray, (width, height), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Optionally display the preprocessed image\n",
        "    if show_preview:\n",
        "        display(Image.fromarray(gray))\n",
        "\n",
        "    return gray\n",
        "\n",
        "# =======================\n",
        "# 📌 Perform OCR on Preprocessed Images\n",
        "# =======================\n",
        "def perform_ocr(images):\n",
        "    \"\"\"\n",
        "    Extracts text and bounding box data from a list of preprocessed images.\n",
        "    Returns extracted text and structured OCR data.\n",
        "    \"\"\"\n",
        "    all_text = []\n",
        "    all_ocr_data = []\n",
        "    custom_config = r'--oem 3 -l eng'  # Use Tesseract's LSTM OCR engine\n",
        "\n",
        "    for gray in images:\n",
        "        # Extract plain text\n",
        "        ocr_text = pytesseract.image_to_string(gray, config=custom_config)\n",
        "        all_text.append(ocr_text)\n",
        "\n",
        "        # Extract detailed OCR data (bounding boxes, confidence)\n",
        "        ocr_data = pytesseract.image_to_data(gray, output_type=pytesseract.Output.DICT)\n",
        "        all_ocr_data.append(ocr_data)\n",
        "\n",
        "    return all_text, all_ocr_data\n",
        "\n",
        "# =======================\n",
        "# 📌 Bounding Box Visualization for OCR Validation\n",
        "# =======================\n",
        "def visualize_bounding_boxes(original_image, processed_image, ocr_data, confidence_threshold=30):\n",
        "    \"\"\"\n",
        "    Draws bounding boxes on the preprocessed image for verification.\n",
        "    Only boxes with confidence above the threshold are displayed.\n",
        "    \"\"\"\n",
        "    # Use a color version of the processed image for drawing\n",
        "    image_copy = cv2.cvtColor(processed_image, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    for i in range(len(ocr_data['text'])):\n",
        "        # Extract bounding box and confidence information\n",
        "        x, y, w, h = ocr_data['left'][i], ocr_data['top'][i], ocr_data['width'][i], ocr_data['height'][i]\n",
        "        conf = int(ocr_data['conf'][i])\n",
        "\n",
        "        # Draw only high-confidence boxes\n",
        "        if conf > confidence_threshold:\n",
        "            image_copy = cv2.rectangle(image_copy, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            text = ocr_data['text'][i].strip()\n",
        "            if text:\n",
        "                # Overlay the recognized text near the bounding box\n",
        "                cv2.putText(image_copy, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1, cv2.LINE_AA)\n",
        "\n",
        "    # Display the image with bounding boxes\n",
        "    plt.figure(figsize=(15, 20))\n",
        "    plt.imshow(cv2.cvtColor(image_copy, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# =======================\n",
        "# 📌 Document Type Detection\n",
        "# =======================\n",
        "def is_scanned_pdf(pdf_path, text_threshold=100):\n",
        "    \"\"\"\n",
        "    Detects if a PDF is scanned or well-structured.\n",
        "    Returns True if the PDF is likely scanned (low text content), False otherwise.\n",
        "    \"\"\"\n",
        "    with fitz.open(pdf_path) as doc:\n",
        "        total_text = \"\".join([page.get_text() for page in doc])\n",
        "\n",
        "    # Consider it scanned if the total extracted text is below the threshold\n",
        "    return len(total_text.strip()) < text_threshold\n",
        "\n",
        "# =======================\n",
        "# 📌 Main Processing Logic (Optimized)\n",
        "# =======================\n",
        "def process_and_index_pdf(pdf_path):\n",
        "    \"\"\"\n",
        "    Process a scanned or well-structured PDF and create a vector index with improved handling for structured PDFs.\n",
        "    \"\"\"\n",
        "    # Check if the document is scanned\n",
        "    is_scanned = is_scanned_pdf(pdf_path)\n",
        "\n",
        "    # Extract text based on document type\n",
        "    if is_scanned:\n",
        "        print(\"📝 Document Type: Scanned (OCR Required)\")\n",
        "        images = pdf_to_images(pdf_path)\n",
        "        preprocessed_images = [preprocess_image(img) for img in images]\n",
        "        ocr_texts, ocr_datasets = perform_ocr(preprocessed_images)\n",
        "        documents = [Document(text=text) for text in ocr_texts]\n",
        "    else:\n",
        "        print(\"✅ Document Type: Well-Structured (No OCR Needed)\")\n",
        "        documents = []\n",
        "        with fitz.open(pdf_path) as doc:\n",
        "            for i, page in enumerate(doc):\n",
        "                # Extract raw text from each page\n",
        "                text = page.get_text()\n",
        "\n",
        "                # Preserve critical newlines for logical chunking\n",
        "                text = \"\\n\".join([line.strip() for line in text.splitlines() if line.strip()])\n",
        "\n",
        "                # Create Document object with metadata\n",
        "                documents.append(Document(\n",
        "                    text=text,\n",
        "                    metadata={\n",
        "                        \"file_name\": os.path.basename(pdf_path),\n",
        "                        \"page_number\": i + 1,\n",
        "                        \"total_pages\": len(doc)\n",
        "                    }\n",
        "                ))\n",
        "\n",
        "    # Create vector index\n",
        "    all_nodes = multi_granularity_chunking(documents, pdf_path=pdf_path)\n",
        "    vector_index = VectorStoreIndex(all_nodes)\n",
        "    print(f\"✅ Indexed {len(all_nodes)} multi-granularity chunks\")\n",
        "\n",
        "    return vector_index\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fCnNYM_rl5-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cpiw3gawXoQ"
      },
      "source": [
        "### 🧩 Multi-Granularity Chunking\n",
        "Splits each document into both fine-grained (sentence-level) and coarse-grained (section/page-level) chunks for better retrieval.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKaRrzKNmb0N"
      },
      "outputs": [],
      "source": [
        "# =======================\n",
        "# 📌 Multi-Granularity Chunking (Optimized for Structured and Scanned PDFs)\n",
        "# =======================\n",
        "def multi_granularity_chunking(documents, pdf_path, text_threshold=100):\n",
        "    \"\"\"\n",
        "    Generate fine, coarse, and logical chunks with separate strategies for structured and scanned PDFs.\n",
        "    - Retains precise section titles for structured PDFs.\n",
        "    - Simplifies chunking for scanned PDFs to reduce noise.\n",
        "    \"\"\"\n",
        "    # Check if the document is scanned\n",
        "    is_scanned = is_scanned_pdf(pdf_path, text_threshold=text_threshold)\n",
        "\n",
        "    fine_nodes = []\n",
        "    coarse_nodes = []\n",
        "    logical_nodes = []\n",
        "\n",
        "    # Fine-grained chunking (sentence-level)\n",
        "    sentence_splitter = SentenceSplitter(\n",
        "        chunk_size=rag_config[\"fine_chunk_size\"],\n",
        "        chunk_overlap=rag_config[\"fine_chunk_overlap\"]\n",
        "    )\n",
        "    for i, doc in enumerate(documents):\n",
        "        nodes = sentence_splitter.get_nodes_from_documents([doc])\n",
        "        for node in nodes:\n",
        "            node.metadata[\"chunk_type\"] = \"fine\"\n",
        "            node.metadata[\"page_number\"] = i + 1\n",
        "        fine_nodes.extend(nodes)\n",
        "\n",
        "    # Coarse-grained chunking (paragraph-level)\n",
        "    coarse_parser = SimpleNodeParser.from_defaults(\n",
        "        chunk_size=rag_config[\"coarse_chunk_size\"]\n",
        "    )\n",
        "    for i, doc in enumerate(documents):\n",
        "        nodes = coarse_parser.get_nodes_from_documents([doc])\n",
        "        for node in nodes:\n",
        "            node.metadata[\"chunk_type\"] = \"coarse\"\n",
        "            node.metadata[\"page_number\"] = i + 1\n",
        "        coarse_nodes.extend(nodes)\n",
        "\n",
        "    # Logical chunking (Structured PDFs)\n",
        "    if not is_scanned:\n",
        "        for doc in documents:\n",
        "            lines = doc.text.split(\"\\n\")\n",
        "            current_chunk = []\n",
        "            collecting = False\n",
        "            section_title = None\n",
        "\n",
        "            for line in lines:\n",
        "                line_strip = line.strip()\n",
        "\n",
        "                # Detect known section headers\n",
        "                if any(anchor in line_strip.upper() for anchor in [\n",
        "                    \"TOTAL ESTIMATED MONTHLY PAYMENT\",\n",
        "                    \"FEES WORKSHEET\",\n",
        "                    \"ORIGINATION CHARGES\",\n",
        "                    \"OTHER CHARGES\"\n",
        "                ]):\n",
        "                    if current_chunk:\n",
        "                        chunk_text = \"\\n\".join(current_chunk)\n",
        "                        logical_nodes.append(TextNode(text=chunk_text, metadata={\"section\": section_title, \"chunk_type\": \"logical\"}))\n",
        "                        current_chunk = []\n",
        "\n",
        "                    collecting = True\n",
        "                    section_title = line_strip\n",
        "                    current_chunk = [line_strip]\n",
        "                    continue\n",
        "\n",
        "                if collecting:\n",
        "                    if line_strip == \"\" and current_chunk:\n",
        "                        chunk_text = \"\\n\".join(current_chunk)\n",
        "                        logical_nodes.append(TextNode(text=chunk_text, metadata={\"section\": section_title, \"chunk_type\": \"logical\"}))\n",
        "                        current_chunk = []\n",
        "                        collecting = False\n",
        "                    else:\n",
        "                        current_chunk.append(line_strip)\n",
        "\n",
        "            # Add remaining chunk\n",
        "            if current_chunk:\n",
        "                chunk_text = \"\\n\".join(current_chunk)\n",
        "                logical_nodes.append(TextNode(text=chunk_text, metadata={\"section\": section_title, \"chunk_type\": \"logical\"}))\n",
        "\n",
        "    # Logical chunking (Scanned PDFs)\n",
        "    else:\n",
        "        for doc in documents:\n",
        "            lines = doc.text.split(\"\\n\")\n",
        "            current_chunk = []\n",
        "            for line in lines:\n",
        "                line_strip = line.strip()\n",
        "                if line_strip:\n",
        "                    current_chunk.append(line_strip)\n",
        "            if current_chunk:\n",
        "                logical_nodes.append(TextNode(\n",
        "                    text=\"\\n\".join(current_chunk),\n",
        "                    metadata={\"chunk_type\": \"logical\"}\n",
        "                ))\n",
        "\n",
        "    # Print summary for verification\n",
        "    print(f\"✅ Final Chunk Counts - Fine: {len(fine_nodes)}, Coarse: {len(coarse_nodes)}, Logical: {len(logical_nodes)}\")\n",
        "\n",
        "    return fine_nodes + coarse_nodes + logical_nodes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P27jpGZ1waOQ"
      },
      "source": [
        "### 📚 Embedding and Index Construction\n",
        "Initializes the Gemini LLM and HuggingFace embedding model, then builds a vector index from multi-granularity chunks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPOWFNl-hlhX",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Set up the custom prompt for the Gemini LLM\n",
        "custom_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", (\n",
        "        \"You are a highly skilled assistant specializing in analyzing mortgage and loan-related documents, \"\n",
        "        \"such as Lender Fee Worksheets and Loan Estimates.\\n\\n\"\n",
        "        \"Your task is to accurately extract and reason over the content retrieved from these documents. \"\n",
        "        \"Always rely on the retrieved context only — do not assume or hallucinate any values or terms.\\n\\n\"\n",
        "        \"When answering:\\n\"\n",
        "        \"- Be precise with all numerical values, dates, and percentages.\\n\"\n",
        "        \"- When totals are requested, check if they need to be calculated from individual components like taxes, insurance, and principal.\\n\"\n",
        "        \"- If a query implies composition or reasoning (e.g., total payment, remaining balance), compute carefully and explain briefly if needed.\\n\"\n",
        "        \"- If the information is not in the retrieved content, respond clearly that it was not found.\\n\"\n",
        "        \"- Use mortgage-specific terminology appropriately and avoid ambiguity.\\n\\n\"\n",
        "        \"You are being used in a legal or financial setting where accuracy and clarity are critical.\"\n",
        "    )),\n",
        "    (\"user\", \"{query_str}\")\n",
        "])\n",
        "\n",
        "# Initialize the Gemini LLM\n",
        "llm = GoogleGenAI(\n",
        "    model=\"models/gemini-2.0-flash\",\n",
        "    prompt=custom_prompt,\n",
        "    max_output_tokens=1024  # Adjust based on your use case\n",
        ")\n",
        "\n",
        "# Initialize the HuggingFace embedding model\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")  # or \"intfloat/e5-base-v2\"\n",
        "Settings.embed_model = embed_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRnAO5IcwjHx"
      },
      "source": [
        "### 🚀 Index the Uploaded PDF\n",
        "Calls the full document processing and indexing function to prepare for RAG-based querying.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQPaeltMhlet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b926c1e-a98c-426b-f1b6-c9551918e710",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📝 Document Type: Scanned (OCR Required)\n",
            "✅ Final Chunk Counts - Fine: 14, Coarse: 5, Logical: 4\n",
            "✅ Indexed 23 multi-granularity chunks\n"
          ]
        }
      ],
      "source": [
        "# =======================\n",
        "# 📌 Run the Indexing\n",
        "# =======================\n",
        "index = process_and_index_pdf(pdf_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JT8UGiiw36W"
      },
      "source": [
        "### 🧠 Full RAG Pipeline Builder\n",
        "Constructs the complete Retrieval-Augmented Generation engine with hybrid retrieval (semantic + keyword), query expansion, and reranking.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLAy6xLahlUS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "5105c675-90f1-4199-ca72-f94abfe89cfe",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:bm25s:Building index from IDs objects\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index contains 23 nodes, using top_k=4\n",
            "✅ Hybrid RAG Pipeline built successfully with 23 nodes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                Stage  Rank      Score  \\\n",
              "0  Original Retrieval     1 -10.724517   \n",
              "1  Original Retrieval     2  -8.564978   \n",
              "2  Original Retrieval     3  -9.127965   \n",
              "3  Original Retrieval     4 -11.105728   \n",
              "4     After Reranking     1  -8.564978   \n",
              "5     After Reranking     2  -9.127965   \n",
              "\n",
              "                                             Content     Page  \n",
              "0  the Property iad what the Property is uncacemb...        2  \n",
              "1  5553) and to Wo successors acd ssngea of NERS)...        2  \n",
              "2  5553) and to Wo successors acd ssngea of NERS)...  Unknown  \n",
              "3  Borrower shall | mcfode xa esch mo alhy.\\nPaym...        2  \n",
              "4  5553) and to Wo successors acd ssngea of NERS)...        2  \n",
              "5  5553) and to Wo successors acd ssngea of NERS)...  Unknown  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05e94775-3e4d-4617-9251-f5e1818e8db0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Stage</th>\n",
              "      <th>Rank</th>\n",
              "      <th>Score</th>\n",
              "      <th>Content</th>\n",
              "      <th>Page</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Original Retrieval</td>\n",
              "      <td>1</td>\n",
              "      <td>-10.724517</td>\n",
              "      <td>the Property iad what the Property is uncacemb...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Original Retrieval</td>\n",
              "      <td>2</td>\n",
              "      <td>-8.564978</td>\n",
              "      <td>5553) and to Wo successors acd ssngea of NERS)...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Original Retrieval</td>\n",
              "      <td>3</td>\n",
              "      <td>-9.127965</td>\n",
              "      <td>5553) and to Wo successors acd ssngea of NERS)...</td>\n",
              "      <td>Unknown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Original Retrieval</td>\n",
              "      <td>4</td>\n",
              "      <td>-11.105728</td>\n",
              "      <td>Borrower shall | mcfode xa esch mo alhy.\\nPaym...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>After Reranking</td>\n",
              "      <td>1</td>\n",
              "      <td>-8.564978</td>\n",
              "      <td>5553) and to Wo successors acd ssngea of NERS)...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>After Reranking</td>\n",
              "      <td>2</td>\n",
              "      <td>-9.127965</td>\n",
              "      <td>5553) and to Wo successors acd ssngea of NERS)...</td>\n",
              "      <td>Unknown</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05e94775-3e4d-4617-9251-f5e1818e8db0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-05e94775-3e4d-4617-9251-f5e1818e8db0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-05e94775-3e4d-4617-9251-f5e1818e8db0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8c422eec-e936-4b5d-ae89-761c4574df01\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8c422eec-e936-4b5d-ae89-761c4574df01')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8c422eec-e936-4b5d-ae89-761c4574df01 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"run_query_with_reranking(\\\"What is the total estimated monthly payment?\\\", top_k=4)\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Stage\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"After Reranking\",\n          \"Original Retrieval\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rank\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Score\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -8.564977645874023,\n          -11.105728149414062\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"the Property iad what the Property is uncacembered, except for eacambrances,\\nBorrower wrecracts fod onl) \\u2018defend\\u2019 generally the tithe to the Propesty ...\",\n          \"5553) and to Wo successors acd ssngea of NERS) wel power cf sale, tho followaag desonbed property Jecased 33\\nMILWAUKEE (Coeaty)\\\\ Wesconsia\\u2019\\nLOTI27pAIN...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Page\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Unknown\",\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def build_rag_pipeline(index):\n",
        "    \"\"\"Build a RAG pipeline with hybrid retrieval, query expansion, and reranking.\"\"\"\n",
        "\n",
        "    # Get all nodes from the index's docstore\n",
        "    nodes = list(index.docstore.docs.values())\n",
        "    num_nodes = len(nodes)\n",
        "\n",
        "    # Set top_k based on configuration\n",
        "    safe_top_k = min(rag_config[\"retrieval_top_k\"], max(1, num_nodes))\n",
        "    print(f\"Index contains {num_nodes} nodes, using top_k={safe_top_k}\")\n",
        "\n",
        "    # Step 1: Define Filters for Each Retrieval Method\n",
        "    filter_by_fine_type = MetadataFilters(filters=[ExactMatchFilter(key=\"chunk_type\", value=\"fine\")])\n",
        "    filter_by_coarse_type = MetadataFilters(filters=[ExactMatchFilter(key=\"chunk_type\", value=\"coarse\")])\n",
        "    filter_by_page_level = MetadataFilters(filters=[ExactMatchFilter(key=\"chunk_type\", value=\"page\")])\n",
        "\n",
        "    # Step 2: Create Individual Retrievers\n",
        "    vector_retriever = index.as_retriever(similarity_top_k=safe_top_k, filters=filter_by_fine_type)\n",
        "    bm25_retriever = BM25Retriever.from_defaults(nodes=nodes, similarity_top_k=safe_top_k)\n",
        "    page_retriever = index.as_retriever(similarity_top_k=safe_top_k, filters=filter_by_page_level)\n",
        "\n",
        "    # Step 3: Hybrid Retriever for Combining Methods\n",
        "    class HybridRetriever(BaseRetriever):\n",
        "        def __init__(self, vector_retriever, bm25_retriever, page_retriever, top_k):\n",
        "            self.vector_retriever = vector_retriever\n",
        "            self.bm25_retriever = bm25_retriever\n",
        "            self.page_retriever = page_retriever\n",
        "            self.top_k = top_k\n",
        "            super().__init__()\n",
        "\n",
        "        def _retrieve(self, query_bundle, **kwargs):\n",
        "            vector_nodes = self.vector_retriever.retrieve(query_bundle)\n",
        "            bm25_nodes = self.bm25_retriever.retrieve(query_bundle)\n",
        "            page_nodes = self.page_retriever.retrieve(query_bundle)\n",
        "\n",
        "            # Combine all retrieved nodes\n",
        "            all_nodes = list(vector_nodes) + list(bm25_nodes) + list(page_nodes)\n",
        "\n",
        "            # Remove duplicates by node_id\n",
        "            unique_nodes = {}\n",
        "            for node in all_nodes:\n",
        "                if node.node_id not in unique_nodes:\n",
        "                    unique_nodes[node.node_id] = node\n",
        "\n",
        "            # Sort nodes by score, highest first\n",
        "            sorted_nodes = sorted(\n",
        "                unique_nodes.values(),\n",
        "                key=lambda x: x.score if hasattr(x, \"score\") and x.score else 0.0,\n",
        "                reverse=True\n",
        "            )\n",
        "\n",
        "            # Return top_k results\n",
        "            return sorted_nodes[:self.top_k]\n",
        "\n",
        "    # Initialize Hybrid Retriever\n",
        "    hybrid_retriever = HybridRetriever(\n",
        "        vector_retriever=vector_retriever,\n",
        "        bm25_retriever=bm25_retriever,\n",
        "        page_retriever=page_retriever,\n",
        "        top_k=safe_top_k\n",
        "    )\n",
        "\n",
        "    # Step 4: Reranker (Optional)\n",
        "    node_postprocessors = []\n",
        "    if num_nodes > 1:\n",
        "        reranker = SentenceTransformerRerank(\n",
        "            model=\"cross-encoder/ms-marco-MiniLM-L-12-v2\",\n",
        "            top_n=min(rag_config[\"rerank_top_n\"], num_nodes)\n",
        "        )\n",
        "        node_postprocessors.append(reranker)\n",
        "\n",
        "    # Step 5: Query Expansion with Fusion Retriever\n",
        "    fusion_retriever = QueryFusionRetriever(\n",
        "        retrievers=[hybrid_retriever],\n",
        "        llm=llm,\n",
        "        num_queries=rag_config[\"num_query_expansions\"],\n",
        "        similarity_top_k=safe_top_k,\n",
        "        mode=\"reciprocal_rerank\"\n",
        "    )\n",
        "\n",
        "    # Step 6: Final Query Engine\n",
        "    query_engine = RetrieverQueryEngine.from_args(\n",
        "        retriever=fusion_retriever,\n",
        "        llm=llm,\n",
        "        node_postprocessors=node_postprocessors\n",
        "    )\n",
        "\n",
        "    print(f\"✅ Hybrid RAG Pipeline built successfully with {num_nodes} nodes.\")\n",
        "\n",
        "    def run_query_with_reranking(query_text, top_k=4):\n",
        "        query_bundle = QueryBundle(query_str=query_text)\n",
        "        nodes = hybrid_retriever._retrieve(query_bundle)\n",
        "        reranked_nodes = reranker.postprocess_nodes(nodes, query_str=query_text) if reranker else nodes\n",
        "\n",
        "        # Prepare DataFrame for comparison\n",
        "        results = []\n",
        "\n",
        "        # Combined Results for Comparison\n",
        "        for i, node in enumerate(nodes):\n",
        "            results.append({\n",
        "                \"Stage\": \"Original Retrieval\",\n",
        "                \"Rank\": i + 1,\n",
        "                \"Score\": node.score,\n",
        "                \"Content\": node.get_text()[:150] + \"...\",\n",
        "                \"Page\": node.metadata.get(\"page_number\", \"Unknown\")\n",
        "            })\n",
        "\n",
        "        for i, node in enumerate(reranked_nodes):\n",
        "            results.append({\n",
        "                \"Stage\": \"After Reranking\",\n",
        "                \"Rank\": i + 1,\n",
        "                \"Score\": node.score,\n",
        "                \"Content\": node.get_text()[:150] + \"...\",\n",
        "                \"Page\": node.metadata.get(\"page_number\", \"Unknown\")\n",
        "            })\n",
        "\n",
        "        # Display the results in a clean table\n",
        "        results_df = pd.DataFrame(results)\n",
        "        display(results_df)\n",
        "\n",
        "    return query_engine, run_query_with_reranking\n",
        "\n",
        "# Rebuild the RAG pipeline\n",
        "rag_engine, run_query_with_reranking = build_rag_pipeline(index)\n",
        "\n",
        "# Example usage of the integrated reranking demonstration\n",
        "run_query_with_reranking(\"What is the total estimated monthly payment?\", top_k=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHXrXah0xI3Z"
      },
      "source": [
        "### 🔍 Run a Sample Query\n",
        "This cell queries the final RAG engine to answer a question using the processed PDF content.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gV3gPW2j2zF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309,
          "referenced_widgets": [
            "6ab9ac65059c417881c88f77939ea815",
            "20cfcea033d64f38ba03659543df0100",
            "6bf9456c2adb4b458b23ad7c5c5e1f60",
            "41dbf549b70149c79611ed1739825452",
            "22da0d3b7b664158b7261acd8a587281",
            "3cdd278d606b49a1ba277db48d8586ae",
            "a49159e56c25491986aa214ad493d54e",
            "011a6643c8574c089d024d6acb18004e",
            "e3eb9d0d72cd4cf5a109102960e1f166",
            "2220f73fc0b948c68014af6e9eba7e20",
            "aad5670a1b764bca89cf3f0a2e5d9730",
            "d1d0120d020d412fad5d3518faea37ae",
            "0883c95802c4436b9d5d5b247f39674f"
          ]
        },
        "outputId": "bc8fe729-2f7e-4eba-b157-155899cee0d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📝 Document Type: Scanned (OCR Required)\n",
            "✅ Final Chunk Counts - Fine: 14, Coarse: 5, Logical: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:bm25s:Building index from IDs objects\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Indexed 23 multi-granularity chunks\n",
            "Index contains 23 nodes, using top_k=4\n",
            "✅ Hybrid RAG Pipeline built successfully with 23 nodes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Dropdown(description='Examples:', layout=Layout(width='90%'), options=('Select a sample prompt'…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ab9ac65059c417881c88f77939ea815"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 🧰 Imports\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "\n",
        "# 📂 Ensure the index is processed correctly\n",
        "index = process_and_index_pdf(pdf_path)\n",
        "rag_engine, run_query_with_reranking = build_rag_pipeline(index)\n",
        "\n",
        "# 📋 Preset prompts\n",
        "preset_prompts = {\n",
        "    \"Who is the mortgagor?\": \"Who is the mortgagor in the document?\",\n",
        "    \"Borrower's owes\": \"How much does the borrower owes the lender?\",\n",
        "    \"Uniform Covenants\": \"What are the Uniform Covenants in detail?\",\n",
        "    \"Parcel Identifier number\": \"What is the parcel identifier number?\",\n",
        "    \"Document number\": \"What is the document number?\",\n",
        "    \"what are escrow items?\": \"what are escrow items?\"\n",
        "\n",
        "}\n",
        "\n",
        "# 🔽 Dropdown for sample prompts\n",
        "prompt_dropdown = widgets.Dropdown(\n",
        "    options=[\"Select a sample prompt\"] + list(preset_prompts.keys()),\n",
        "    description='Examples:',\n",
        "    layout=widgets.Layout(width='90%')\n",
        ")\n",
        "\n",
        "# 📝 Multiline text input\n",
        "query_input = widgets.Textarea(\n",
        "    placeholder='Type or select a query...',\n",
        "    description='Query:',\n",
        "    layout=widgets.Layout(width='90%', height='120px')\n",
        ")\n",
        "\n",
        "# 🔘 Submit button\n",
        "submit_button = widgets.Button(\n",
        "    description='Submit',\n",
        "    button_style='success',\n",
        "    tooltip='Submit your query',\n",
        "    icon='search'\n",
        ")\n",
        "\n",
        "# 📦 Output box\n",
        "output_box = widgets.Output()\n",
        "\n",
        "# 🧠 Define query execution function\n",
        "def run_query(query_text):\n",
        "    try:\n",
        "        # Strip any leading or trailing whitespace\n",
        "        cleaned_query = query_text.strip()\n",
        "\n",
        "        # Run the query\n",
        "        response = rag_engine.query(cleaned_query).response\n",
        "\n",
        "        # Format the response in a styled box with black text\n",
        "        formatted_response = f\"\"\"\n",
        "        <div style=\"\n",
        "            background-color: #f9f9f9;\n",
        "            border-left: 6px solid #007bff;\n",
        "            padding: 15px;\n",
        "            margin-bottom: 15px;\n",
        "            border-radius: 8px;\n",
        "            font-family: Arial, sans-serif;\n",
        "            color: #000000;  /* Ensure text is black */\n",
        "        \">\n",
        "        <h3>📝 Query:</h3>\n",
        "        <p><strong>{cleaned_query}</strong></p>\n",
        "        <hr>\n",
        "        <h3>📄 Response:</h3>\n",
        "        <p>{response}</p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        # Display formatted HTML\n",
        "        with output_box:\n",
        "            clear_output()\n",
        "            display(HTML(formatted_response))\n",
        "\n",
        "    except Exception as e:\n",
        "        # Display error in styled box\n",
        "        with output_box:\n",
        "            clear_output()\n",
        "            display(HTML(f\"\"\"\n",
        "            <div style=\"\n",
        "                background-color: #f8d7da;\n",
        "                border-left: 6px solid #dc3545;\n",
        "                padding: 15px;\n",
        "                margin-bottom: 15px;\n",
        "                border-radius: 8px;\n",
        "                font-family: Arial, sans-serif;\n",
        "                color: #000000;  /* Ensure text is black */\n",
        "            \">\n",
        "            <h3>❌ Error:</h3>\n",
        "            <p>{str(e)}</p>\n",
        "            </div>\n",
        "            \"\"\"))\n",
        "\n",
        "# 🧩 Handle prompt selection\n",
        "def on_prompt_change(change):\n",
        "    if change.new in preset_prompts:\n",
        "        query_input.value = preset_prompts[change.new]\n",
        "\n",
        "prompt_dropdown.observe(on_prompt_change, names='value')\n",
        "\n",
        "# 🚀 Handle query submission\n",
        "def on_submit_click(b):\n",
        "    run_query(query_input.value.strip())\n",
        "\n",
        "submit_button.on_click(on_submit_click)\n",
        "\n",
        "# 🎯 Display the interactive UI\n",
        "display(widgets.VBox([\n",
        "    prompt_dropdown,\n",
        "    query_input,\n",
        "    submit_button,\n",
        "    output_box\n",
        "]))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ctMyXE5I2ATs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6ab9ac65059c417881c88f77939ea815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20cfcea033d64f38ba03659543df0100",
              "IPY_MODEL_6bf9456c2adb4b458b23ad7c5c5e1f60",
              "IPY_MODEL_41dbf549b70149c79611ed1739825452",
              "IPY_MODEL_22da0d3b7b664158b7261acd8a587281"
            ],
            "layout": "IPY_MODEL_3cdd278d606b49a1ba277db48d8586ae"
          }
        },
        "20cfcea033d64f38ba03659543df0100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Select a sample prompt",
              "Who is the mortgagor?",
              "Borrower's owes",
              "Uniform Covenants",
              "Parcel Identifier number",
              "Document number",
              "what are escrow items?"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Examples:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_a49159e56c25491986aa214ad493d54e",
            "style": "IPY_MODEL_011a6643c8574c089d024d6acb18004e"
          }
        },
        "6bf9456c2adb4b458b23ad7c5c5e1f60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Query:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_e3eb9d0d72cd4cf5a109102960e1f166",
            "placeholder": "Type or select a query...",
            "rows": null,
            "style": "IPY_MODEL_2220f73fc0b948c68014af6e9eba7e20",
            "value": ""
          }
        },
        "41dbf549b70149c79611ed1739825452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Submit",
            "disabled": false,
            "icon": "search",
            "layout": "IPY_MODEL_aad5670a1b764bca89cf3f0a2e5d9730",
            "style": "IPY_MODEL_d1d0120d020d412fad5d3518faea37ae",
            "tooltip": "Submit your query"
          }
        },
        "22da0d3b7b664158b7261acd8a587281": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_0883c95802c4436b9d5d5b247f39674f",
            "msg_id": "",
            "outputs": []
          }
        },
        "3cdd278d606b49a1ba277db48d8586ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a49159e56c25491986aa214ad493d54e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "90%"
          }
        },
        "011a6643c8574c089d024d6acb18004e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3eb9d0d72cd4cf5a109102960e1f166": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "120px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "90%"
          }
        },
        "2220f73fc0b948c68014af6e9eba7e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aad5670a1b764bca89cf3f0a2e5d9730": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1d0120d020d412fad5d3518faea37ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "0883c95802c4436b9d5d5b247f39674f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}